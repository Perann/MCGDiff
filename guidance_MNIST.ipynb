{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1a3f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c27a966",
   "metadata": {},
   "source": [
    "Loading pretrained diff model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fe8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Fetching 4 files: 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "\n",
    "pipe.unet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1038c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 123.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAALG0lEQVR4nO3cP4ic5RrG4Xd21yRGLSYhLmijICgKggnaaZFiLWzUQrGw0UrERtQihWKnRKysREFBiAjiH7BRQkQRLARRhFRWohJMYNFl2dXs7OluDuLhfM9rZjKZXFe9d2ayO5ufX+Ez2t3d3W0A0FpbuthvAID5IQoAhCgAEKIAQIgCACEKAIQoABCiAECsDP7ClcFfGv6/OID5sbOz83+/xpMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQAy+cue4HcD8mNa/yZ4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGLwQTy4lIxGo/LG0UcuJQ7iATB1ogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQrqSykOb54uk8v7fW+i7Msjg8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDE4IN4PUey5v3wF/y3WX1eew/OTSaTC/xO/pmDeJc3TwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMfggHlwsPYfqrr766vLm4MGD5c2rr75a3jzwwAPlTWutnT9/vrx5++23y5snnniivOl5bw7v/TvT+v55UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI0e7Aa2MrK/XbeT2HzFhcvZ+HJ598srx55ZVXypuez/gsj7otLc3mv+GOHj1a3pw6daq8mdXfZ1FNJpPyZsjvoJ8KACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQDiIR5een+0VV1zR9VpffvlleXPXXXeVNz/88EN588knn5Q3V155ZXnTWms33XRTeXPvvfeWN7///nt589BDD5U3J0+eLG96zfJw4az0/A4OOaLnSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcCV1BnouNM77967n/Y3H467XOnfuXHnz8ccflzcPP/xwebOzszOTTWutXXvtteXNiRMnypu77767vPn111/Lm1tuuaW8aa21zc3N8mber6TO6vfdlVQASkQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiMEH8ZaXl6f9Xi4JPYereg6ZnTlzprxprbWlpdl0vuf7sH///q7Xevfdd8ub+++/v7yZ9yOEPUfdeo7v/fzzz+XNoUOHypv77ruvvGmttZMnT3btGPZ58KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEIMP4q2srJT/8FkeGOt5rZ4DY++88055c+7cufLmqaeeKm9a6ztc2PO9m0wm5U3P97u11u68887y5ptvvul6raqe713v0cJZ/ZyeffbZ8ubYsWPlzenTp8ub1lpbW1srbzY3N7tea55N6/PgSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgBh/E6zm0toh+++238ubDDz8sbx5//PHyprX+Y2uzMMsDiT3H92Z1VHGWev5OV111VXlz4sSJ8ubo0aPlTWutHTx4sLzZ3t4ubxbxZ+sgHgAlogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQK0O/cFZXJ2dpz5495U3PBcnbbrutvOm9djrPP6d5vzq5iHo+RxsbG+XN+vp6eTPkYuc/6fl9+vbbb7te63LkSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgBh/EW0Srq6vlTc+Bse+++6686TXvRwjn2SIe7Ov5POzdu7e8OXz4cHnzxRdflDettfbTTz+VN/N8KLLXtN6fJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAuKwP4u3bt+9iv4X/qfc427wf8WK2JpNJebO2tlbe3HrrreXNyy+/XN601trZs2e7dotmWgccPSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxOCDePN+aK3n/d1www3lzV9//VXeXHPNNeVNzyGz1qZ3JIuLr+czfv3115c3x48fL2/W19fLm1OnTpU3TJ8nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAYfBBvEW1vb5c3+/fvL2/G43F503vYrmc378cOF03v97tn995775U3N998c3nz0ksvlTe//PJLecP0eVIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIC7rK6lbW1szeZ3Dhw+XN6urq12vdebMma4dfVdIezb79u0rb1pr7a233ipvej57r732Wnnz4osvljfMJ08KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALEwB/FGo1F5c/bs2fJme3u7vOl5b+fPny9vFtWsDtUdOHCgvHn00UfLm2PHjpU3rbU2Ho/Lm48++qi8ef7558ubP//8s7xhPnlSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiFOYjX48cffyxvPv300/LmjjvuKG/W19fLm3k3mUy6dsvLy+XN2tpaefPGG2+UN9ddd11588cff5Q3rbX23HPPlTevv/56ebO1tVXeMHs9Rx+H8KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEAtzEK/nOFTP5vTp0+XNPffcU94cOXKkvGmtta+//rq8GY/H5c2DDz5Y3mxubpY3rbX2wgsvlDc33nhjebNnz57y5s033yxvnn766fKmtdY2Nja6diym0Wg0lT/XkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAjHYHXoVbXl6e9nuZuZ6DeKurq+XNV199Vd4cOnSovGmt76jbZDIpb3o+Dz3vrbXWdnZ2yptnnnmmvPn888/Lm++//768gQuh5/d2yL95nhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiMFXUldWVsp/eM8V0nnX83e6/fbby5tHHnmkvGmttccee6y82bt3b3mztbVV3rz//vvlTWutffbZZ+XNBx98UN4sLdX/G6nn8zAajcob+Luez96Qy6qeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBi8EG85eXlab8XLoCew4Xj8bi82djYKG96jui1tpiHFeHfGnLc7u+G/C55UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/HmVO8RuNFodIHfCTCPev6NGHJEz5MCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQKwM/cKeQ2u9R91w2A64ODwpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCDr6S6eAqw+DwpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMTgg3g9eo7ojUajKbyTfzbv7w8uFX6X/p15+v55UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI0W7PJSYAFpInBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAOI/n7wsZOgFCOEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    image = pipe(batch_size=1).images[0]\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be9552",
   "metadata": {},
   "source": [
    "Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86940b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=0.05):\n",
    "    \"\"\"\n",
    "    x_true: tensor [1, H, W]\n",
    "    retourne: mask, y\n",
    "    \"\"\"\n",
    "    _, H, W = x_true.shape\n",
    "    spatial_mask = (torch.rand(H, W, device=x_true.device) > missing_ratio).float()\n",
    "    mask = spatial_mask.unsqueeze(0)  # broadcast sur le canal\n",
    "\n",
    "    noise = sigma_noise * torch.randn_like(x_true)\n",
    "    y = mask * x_true + noise\n",
    "    return mask, y\n",
    "\n",
    "\n",
    "def log_likelihood_grad(x, y, mask, sigma_noise):\n",
    "    \"\"\"\n",
    "    Gradient de log p(y|x) pour inpainting\n",
    "    \"\"\"\n",
    "    return mask * (y - mask * x) / (sigma_noise ** 2)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def guided_reverse_step(pipe, x_t, t, mask, y, sigma_noise, guidance_scale=1.0):\n",
    "    \"\"\"\n",
    "    x_t: [batch, 1, H, W]\n",
    "    t: int, step\n",
    "    mask, y: inpainting observation\n",
    "    guidance_scale: float\n",
    "    \"\"\"\n",
    "    # Prédiction du bruit par le modèle\n",
    "    eps = pipe.unet(x_t, t).sample\n",
    "\n",
    "    # Gradient de vraisemblance\n",
    "    grad = log_likelihood_grad(x_t, y, mask, sigma_noise)\n",
    "\n",
    "    # Pas reverse DDPM avec guidance\n",
    "    alpha_t = pipe.scheduler.alphas_cumprod[t]\n",
    "    alpha_prev = pipe.scheduler.alphas_cumprod[t-1] if t > 0 else torch.tensor(1.0, device=x_t.device)\n",
    "\n",
    "    x_prev = (\n",
    "        1 / torch.sqrt(alpha_t) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * eps)\n",
    "    )\n",
    "\n",
    "    # Ajouter guidance\n",
    "    x_prev = x_prev + guidance_scale * grad\n",
    "\n",
    "    # Ajouter bruit si pas le dernier step\n",
    "    if t > 0:\n",
    "        beta_t = 1 - alpha_t\n",
    "        noise = torch.randn_like(x_t)\n",
    "        x_prev = x_prev + torch.sqrt(beta_t) * noise\n",
    "\n",
    "    return x_prev\n",
    "\n",
    "def smc_guided_sampling(pipe, y, mask, sigma_noise, num_particles=5, num_steps=50, guidance_scale=1.0):\n",
    "    \"\"\"\n",
    "    pipe: DDPMPipeline\n",
    "    y, mask: observations\n",
    "    \"\"\"\n",
    "    batch_size = 1\n",
    "    H, W = y.shape[1], y.shape[2]\n",
    "\n",
    "    # Initialisation des particules\n",
    "    particles = torch.randn(num_particles, 1, H, W, device=y.device)\n",
    "\n",
    "    for t in reversed(range(num_steps)):\n",
    "        for i in range(num_particles):\n",
    "            particles[i:i+1] = guided_reverse_step(\n",
    "                pipe, particles[i:i+1], t, mask, y, sigma_noise, guidance_scale\n",
    "            )\n",
    "\n",
    "        # Resampling possible selon poids (facultatif pour MNIST simple)\n",
    "\n",
    "    return particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 142.60it/s]\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 130.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline, DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ========================\n",
    "# 1️⃣ Charger le modèle MNIST\n",
    "# ========================\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "pipe.unet.eval()\n",
    "\n",
    "scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "num_inference_steps = 50\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "# ========================\n",
    "# 2️⃣ Générer une image MNIST\n",
    "# ========================\n",
    "with torch.no_grad():\n",
    "    x_true_pil = pipe(batch_size=1).images[0]\n",
    "\n",
    "to_tensor = T.ToTensor()\n",
    "x_true = to_tensor(x_true_pil).to(device)\n",
    "x_true = x_true * 2 - 1  # [-1,1]\n",
    "\n",
    "# ========================\n",
    "# 3️⃣ Masque et observation\n",
    "# ========================\n",
    "def create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=0.05):\n",
    "    _, H, W = x_true.shape\n",
    "    spatial_mask = (torch.rand(H, W, device=x_true.device) > missing_ratio).float()\n",
    "    mask = spatial_mask.unsqueeze(0)\n",
    "    noise = sigma_noise * torch.randn_like(x_true)\n",
    "    y = mask * x_true + noise\n",
    "    return mask, y\n",
    "\n",
    "sigma_noise = 0\n",
    "mask, y = create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=sigma_noise)\n",
    "\n",
    "# ========================\n",
    "# 4️⃣ Gradient de log-vraisemblance\n",
    "# ========================\n",
    "def log_likelihood_grad(x, y, mask, sigma_noise):\n",
    "    return mask * (y - mask * x) / (sigma_noise ** 2)\n",
    "\n",
    "def log_likelihood(x, y, mask, sigma_noise):\n",
    "    return -0.5 * ((mask * (y - mask * x))**2 / (sigma_noise**2)).sum(dim=[1,2,3])\n",
    "\n",
    "# ========================\n",
    "# 5️⃣ SMC-guided sampling avec poids et resampling\n",
    "# ========================\n",
    "@torch.no_grad()\n",
    "def smc_guided_sampling(pipe, y, mask, sigma_noise, num_particles=5, guidance_scale=0.05, num_steps=50):\n",
    "    _, H, W = y.shape\n",
    "    particles = torch.randn(num_particles, 1, H, W, device=y.device)  # x_T\n",
    "    weights = torch.ones(num_particles, device=y.device) / num_particles  # poids initiaux\n",
    "\n",
    "    timesteps = scheduler.timesteps\n",
    "    for t_idx, t in enumerate(timesteps):\n",
    "        for i in range(num_particles):\n",
    "            x_t = particles[i:i+1]\n",
    "\n",
    "            # Prédiction epsilon\n",
    "            eps = pipe.unet(x_t, t)[\"sample\"]\n",
    "\n",
    "            # Reverse step DDPM\n",
    "            alpha_t = scheduler.alphas_cumprod[t]\n",
    "            beta_t = 1 - alpha_t\n",
    "            x_prev = (1 / torch.sqrt(alpha_t)) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * eps)\n",
    "\n",
    "            # Guidance gradient\n",
    "            grad = log_likelihood_grad(x_prev, y, mask, sigma_noise)\n",
    "            x_prev = x_prev + guidance_scale * grad\n",
    "\n",
    "            # Ajouter bruit si pas dernier step\n",
    "            if t_idx < len(timesteps) - 1:\n",
    "                x_prev = x_prev + torch.sqrt(beta_t) * torch.randn_like(x_prev)\n",
    "\n",
    "            particles[i:i+1] = x_prev\n",
    "\n",
    "        # ========================\n",
    "        # Mise à jour des poids\n",
    "        # ========================\n",
    "        logw = log_likelihood(particles, y, mask, sigma_noise)\n",
    "        logw = logw - logw.max()  # stabilité numérique\n",
    "        w = torch.exp(logw)\n",
    "        w = w / w.sum()\n",
    "        weights = w\n",
    "\n",
    "        # ========================\n",
    "        # Resampling multinomial si variance des poids trop grande\n",
    "        # ========================\n",
    "        ess = 1.0 / (weights**2).sum()\n",
    "        if ess < num_particles / 2:\n",
    "            indices = torch.multinomial(weights, num_particles, replacement=True)\n",
    "            particles = particles[indices]\n",
    "            weights = torch.ones(num_particles, device=y.device) / num_particles\n",
    "\n",
    "    return particles, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2601d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 5\n",
    "particles, weights = smc_guided_sampling(pipe, y, mask, sigma_noise,\n",
    "                                         num_particles=num_particles,\n",
    "                                         guidance_scale=0.001,\n",
    "                                         num_steps=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5257f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(img, title=None):\n",
    "    img = img.detach().cpu().squeeze(0)\n",
    "    plt.imshow(img.clamp(0, 1), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "show(x_true, \"x true\")\n",
    "plt.subplot(1, 3, 2)\n",
    "show(mask, \"mask\")\n",
    "plt.subplot(1, 3, 3)\n",
    "show(y, \"observation y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c1243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAACuCAYAAAD+kpJ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvNElEQVR4nO3de5xP9b7H8ffcL2aMO5G7bJEilzq2TCmXbrZ2ol1tYSttKYowwtxkSEXF7rLLkFRK6XKOdFGdOtLNTtJRIVQShRlmjBkzs84fjtmt9f2O+c6gcXk9Hw+Px/5+5rPW77vW7zuz87Xm/QvxPM8TAAAAAAAADiu0sicAAAAAAABwImATBQAAAAAAwAGbKAAAAAAAAA7YRAEAAAAAAHDAJgoAAAAAAIADNlEAAAAAAAAcsIkCAAAAAADggE0UAAAAAAAAB2yiAAAAAAAAOGATBTiM559/XjVq1FBOTk65j23SpImuuOKKYzCr49u8efMUEhKizZs3l9TOP/98jR07tvImBWe298/FoEGD1KRJk2MyJ5waWHuoLKw9VBbWHioLa+/IsIkS8NNPPyklJUWrV6+u7KmgkhUVFSk5OVm33Xab4uLiKns6J7Rx48Zpzpw5+vnnnyt7Kvh/U6dO1csvv1zZ0yjVtm3bNH78eF100UWKj49XSEiI3nvvvcqeFo6C433tLV++XEOGDFHLli0VGxurZs2aaejQodq2bVtlTw1H6Hhfe++//7769Omjhg0bKjo6WvXq1VPv3r21YsWKyp4ajtDxvvaCbrrpJoWEhJyS/xh4sjne196hzRzbn+P57w1sogT89NNPSk1NZRMFeu211/TNN9/o5ptvruypnPD+9Kc/qWrVqvrHP/5R2VPB/yvt/1T/+te/Ki8vT40bN/79J/Ub33zzjaZPn66tW7eqbdu2lToXHF3H+9obN26c3nvvPV111VV66KGHdO211+r5559X+/btj+v/oEPZjve19+233yo0NFS33HKL5syZozFjxujnn39Wt27dtGzZskqdG47M8b72fuuzzz7TvHnzFB0dXdlTwVFwoqy9tLQ0LViwwPenWrVqlT2tUoVX9gROdPv27VNsbGxlTwPHQGZmpv74xz+qQYMGlT2VI5Kbm6sqVapU6hxCQ0PVr18/PfXUU0pNTVVISEilzudU5Xme9u/fr5iYmFJ7wsLCFBYW9jvOyq5Dhw7auXOnatSoocWLF+uaa66p7CnhCJxIa++BBx5Q165dFRr6739n6t27txITEzV79mxNmTKlEmeH8jqR1t7QoUM1dOhQX2348OFq1qyZZs2apd69e1fSzFARJ9LaO8TzPN1+++0aOHCgli9fXtnTQQWdiGvv0ksvVceOHSt7Gs5OmidR8vLy1KpVK7Vq1Up5eXkl9V27dum0005Tly5dVFRUdNhzvPfee+rUqZMkafDgwSWPEs2bN0+SdOGFF+qss87SqlWr1K1bN8XGxmrChAmSpJCQEKWkpBjnbNKkiQYNGuSrZWVladSoUWrYsKGioqLUokULTZ8+XcXFxRW/AfB59913FRISoiVLlhhfe+aZZxQSEqKVK1eWevz+/fu1bNkyXXLJJcbXCgsLlZ6erubNmysqKkpNmjTRhAkTlJ+fbz3Xm2++qXbt2ik6OlqtW7fWSy+95Pv6gQMHlJqaqjPOOEPR0dGqWbOmunbtqrfeesvX9/XXX6tfv36qUaOGoqOj1bFjR7366qu+nkOPxP33f/+3hg8frjp16uj000/X4sWLS+pBjz32mEJCQrR27dpyvZYkffXVV+revbtiYmJ0+umna8qUKaWu4x49emjLli085VWKlJQUhYSE6Ouvv1b//v1VtWpV1axZUyNHjtT+/ft9vZmZmerevbvq1KmjqKgotW7dWo888ohxzkO5PG+88YY6duyomJiYkvc7NzdX8+fPL/k5d+jnVGm/I/v6668rMTFR8fHxqlq1qjp16qRnnnnmsNdUXFysWbNmqU2bNoqOjlbdunU1bNgw7d69u8z7ER8frxo1apTZhyPH2vPr1q2bbwPlUK1GjRpat25dmcfDHWuvbLGxsapdu7aysrIqdDzsWHt2CxYs0Nq1a3XPPfc4H4PyYe2Vbu/evWX+ff14cdI8iRITE6P58+frj3/8o+6++2498MADkqRbb71V2dnZmjdvXpm7bWeeeabS0tI0efJk3XzzzbrgggskSV26dCnp2blzpy699FJde+21uuGGG1S3bt1yzXPfvn1KTEzU1q1bNWzYMDVq1EgffvihkpKStG3bNs2aNat8Fw6rCy+8UA0bNtTChQt11VVX+b62cOFCNW/eXP/xH/9R6vGrVq1SQUGBzj33XONrQ4cO1fz589WvXz+NHj1aH3/8sTIyMrRu3Tpj02b9+vUaMGCAbrnlFt14443KzMzUNddco2XLlqlHjx6SDv4wzcjI0NChQ9W5c2ft2bNHn332mf71r3+V9Hz11VclT8WMHz9eVapU0fPPP6++ffvqxRdfNK5x+PDhql27tiZPnqzc3FxdfvnliouL0/PPP6/ExERf76JFi9SmTRudddZZ5Xqtn3/+WRdddJEKCwtL+h5//PFSd707dOggSVqxYoXat29f6r0/1fXv319NmjRRRkaGPvroIz300EPavXu3nnrqqZKeRx55RG3atFGfPn0UHh6u1157TcOHD1dxcbFuvfVW3/m++eYb/eUvf9GwYcN000036Q9/+IMWLFhQst4O/bpa8+bNS53TvHnzNGTIELVp00ZJSUmqVq2aPv/8cy1btkzXXXddqccNGzZM8+bN0+DBg3X77bdr06ZNmj17tj7//HOtWLFCERERR3i3cDSx9kqXk5OjnJwc1apVq1zHwQ1rz2/Pnj0qKCjQr7/+qqeeekpr164t+Uc7HF2svX/bu3evxo0bpwkTJqhevXoutw9HgLXnd9FFFyknJ0eRkZHq1auX7r//fp1xxhllHldpvJNMUlKSFxoa6r3//vveCy+84EnyZs2a5Xz8p59+6knyMjMzja8lJiZ6krxHH33U+JokLzk52ag3btzYu/HGG0vG6enpXpUqVbxvv/3W1zd+/HgvLCzM+/77753nisNLSkryoqKivKysrJLajh07vPDwcOt79VtPPPGEJ8n78ssvffXVq1d7kryhQ4f66mPGjPEkee+8805JrXHjxp4k78UXXyypZWdne6eddprXvn37kto555zjXX755Yedz8UXX+y1bdvW279/f0mtuLjY69Kli3fGGWeU1DIzMz1JXteuXb3CwkLfOf7yl794derU8dW3bdvmhYaGemlpaeV+rVGjRnmSvI8//riktmPHDi8hIcGT5G3atMm4jsjISO/vf//7Ya/1VJWcnOxJ8vr06eOrDx8+3JPkffHFFyW1ffv2Gcf36tXLa9asma92aA0uW7bM6K9SpYrvZ9Mhh9bQofcvKyvLi4+P98477zwvLy/P11tcXFzyv2+88UavcePGJeMPPvjAk+QtXLjQd8yyZcus9cM59LP83XffdT4G7lh7ZUtPT/ckecuXLy/3sSgda8+uV69eniRPkhcZGekNGzbMmAeODGvPNGbMGK9p06Yl//3XuHHjMv/7FOXH2vNbtGiRN2jQIG/+/PnekiVLvIkTJ3qxsbFerVq1juu/F580v85zSEpKitq0aaMbb7xRw4cPV2Jiom6//fajdv6oqCgNHjy4wse/8MILuuCCC1S9enX9+uuvJX8uueQSFRUV6f333z9qcz3VDRw4UPn5+Vq8eHFJbdGiRSosLNQNN9xw2GN37twpSapevbqvvnTpUknSnXfe6auPHj1akvRf//Vfvnr9+vV9T4lUrVpVAwcO1Oeff14SUFitWjV99dVXWr9+vXUuu3bt0jvvvKP+/ftr7969JWtm586d6tWrl9avX6+tW7f6jrnpppuMJ68GDBigHTt2+D7hZPHixSouLtaAAQPK/VpLly7V+eefr86dO5ecr3bt2rr++uut1yGpZN2jdMF/Wbjtttsk/XvtSfI97ZOdna1ff/1ViYmJ+u6775Sdne07vmnTpurVq1eF5/PWW29p7969Gj9+vBEyd7hsmxdeeEEJCQnq0aOH72ddhw4dFBcXp3fffbfCc8Kxwdqze//995Wamqr+/fure/fuFboWHB5rz2/atGl688039eSTT+r8889XQUGBCgsLK3w9KB1r76Bvv/1WDz74oGbMmKGoqKgKzx/uWHsH9e/fX5mZmRo4cKD69u2r9PR0vfHGG9q5c+dx/WtlJ82v8xwSGRmpuXPnqlOnToqOjlZmZuZRDbFs0KCBIiMjK3z8+vXrtWbNGtWuXdv69R07dlT43PBr1aqVOnXqpIULF+pvf/ubpIO/ynP++eerRYsWTufwPM833rJli0JDQ43j69Wrp2rVqmnLli2+eosWLYz117JlS0nS5s2bVa9ePaWlpelPf/qTWrZsqbPOOku9e/fWX//6V5199tmSpA0bNsjzPE2aNEmTJk2yznPHjh2+ANymTZsaPb1791ZCQoIWLVqkiy++WNLBTaV27dqVzKk8r7Vlyxadd955xtf/8Ic/WI+TDt5PQmUPL/joYvPmzRUaGur7ndUVK1YoOTlZK1eu1L59+3z92dnZSkhIKBnb1kJ5bNy4UZJKft3L1fr165Wdna06depYv87PuuMPa8/09ddf66qrrtJZZ52lJ554olzzgDvWnl+7du1K/vcNN9ygc889V4MGDfL9oxCODtbeQSNHjlSXLl109dVXl+t1UXGsvdJ17dpV5513nt5+++1yH/t7Oek2USTpjTfekHQwHHT9+vVHvKh+63ApxzbBcJzi4mL16NFDY8eOtfYf+sssjo6BAwdq5MiR+vHHH5Wfn6+PPvpIs2fPLvO4mjVrSpJ2796t008/3fj60dwI6NatmzZu3KhXXnlFb775pp544gnNnDlTjz76qIYOHVoS1DpmzJhSd5iDmzq2dRoVFaW+fftqyZIl+sc//qHt27drxYoVmjp1aklPRV6rPLKyssgUKKfgWtu4caMuvvhitWrVSg888IAaNmyoyMhILV26VDNnzjSCfcv7M+toKS4uVp06dbRw4ULr10vbSMbx41Rfez/88IN69uyphIQELV26VPHx8UdzmjiMU33t/VZkZKT69OmjadOmKS8vr9Ku7VRxKq69d955R8uWLdNLL73k+wt8YWGh8vLytHnzZtWoUUNVq1Y92tPGb5yKa+9wGjZsqG+++eZIpnZMnXSbKGvWrFFaWpoGDx6s1atXa+jQofryyy99O3WHU9G/HFevXt1ITi8oKNC2bdt8tebNmysnJ8f6qS84+q699lrdeeedevbZZ5WXl6eIiIiSX105nFatWkmSNm3apLZt25bUGzdurOLiYq1fv15nnnlmSX379u3KysoyPmv90JMdv11X3377raSDSdqH1KhRQ4MHD9bgwYOVk5Ojbt26KSUlRUOHDlWzZs0kSREREUe8bgYMGKD58+dr+fLlWrdunTzP892P8rxW48aNrb+CVNoPvK1bt6qgoMB332AKbvxu2LBBxcXFJevltddeU35+vl599VU1atSopK+8v6Lg+rPuUADZ2rVry7WB1rx5c7399tv64x//yH/0nyBYe/+2c+dO9ezZU/n5+Vq+fLlOO+20Cp0Hblh7h5eXlyfP87R3715+nh5lrD3p+++/lyT9+c9/Nr62detWNW3aVDNnztSoUaPKdV4cHmvv8L777rvj+h/cTqpMlAMHDmjQoEGqX7++HnzwQc2bN0/bt2/XHXfc4XyOKlWqSFK5P0quefPmRp7J448/bjyJ0r9/f61cubLkaZnfysrK4ndej7JatWrp0ksv1dNPP62FCxeqd+/eTk9CdOjQQZGRkfrss8989csuu0ySjE9ROvRpUJdffrmv/tNPP/k+sWfPnj166qmn1K5du5Lk80P5K4fExcWpRYsWJR+ZXKdOHV144YV67LHHjE05Sfrll1/KvJ5DLrnkEtWoUUOLFi3SokWL1LlzZ98P8PK81mWXXaaPPvpIn3zyie/rpe1Er1q1SpL/065gmjNnjm/88MMPS5IuvfRSSSrJuvntr5plZ2crMzOzXK9TpUoVp59zPXv2VHx8vDIyMoyP3gv+uttv9e/fX0VFRUpPTze+VlhYyMd1HodYewfl5ubqsssu09atW7V06dLj+9MBThKsvYNsj71nZWXpxRdfVMOGDUt9XB4Vx9qTunfvriVLlhh/ateurY4dO2rJkiW68sory5w7yoe1d5Dt7zFLly7VqlWr1Lt37zLnXVlOqidRpkyZotWrV2v58uWKj4/X2WefrcmTJ2vixInq169fyV+AD6d58+aqVq2aHn30UcXHx6tKlSo677zzyvyVoKFDh+qWW27R1VdfrR49euiLL77QG2+8YfyF/a677tKrr76qK664QoMGDVKHDh2Um5urL7/8UosXL9bmzZv5dYejbODAgerXr58kWb/BbaKjo9WzZ0+9/fbbSktLK6mfc845uvHGG/X4448rKytLiYmJ+uSTTzR//nz17dtXF110ke88LVu21N/+9jd9+umnqlu3rubOnavt27f7fgC2bt1aF154oTp06KAaNWros88+0+LFizVixIiSnjlz5qhr165q27atbrrpJjVr1kzbt2/XypUr9eOPP+qLL75wuq6IiAj9+c9/1nPPPafc3Fzdd999Ro/ra40dO1YLFixQ7969NXLkyJKPOG7cuLHWrFljnPett95So0aN+HjjMmzatEl9+vRR7969tXLlSj399NO67rrrdM4550g6+H9ykZGRuvLKKzVs2DDl5OTon//8p+rUqWPd+CpNhw4d9Pbbb+uBBx5Q/fr11bRpU2vGTdWqVTVz5kwNHTpUnTp10nXXXafq1avriy++0L59+zR//nzr+RMTEzVs2DBlZGRo9erV6tmzpyIiIrR+/Xq98MILevDBB0u+L0szZcoUSQc/dluSFixYoP/5n/+RJE2cONH5WuGGtXfQ9ddfr08++URDhgzRunXrtG7dupKvxcXFqW/fvs7XCjesvYMuvfRSnX766TrvvPNUp04dff/998rMzNRPP/2kRYsWOV8n3LH2pEaNGvmedDhk1KhRqlu3Lj/zjhHW3kFdunRR+/bt1bFjRyUkJOhf//qX5s6dq4YNGx7fH+3+u38e0DGyatUqLzw83Lvtttt89cLCQq9Tp05e/fr1vd27dzud65VXXvFat27thYeH+z7uODEx0WvTpo31mKKiIm/cuHFerVq1vNjYWK9Xr17ehg0bjI849jzP27t3r5eUlOS1aNHCi4yM9GrVquV16dLFu++++7yCgoLyXjrKkJ+f71WvXt1LSEgo10cEvvTSS15ISIjx8VoHDhzwUlNTvaZNm3oRERFew4YNvaSkJN9HAnvevz8a7o033vDOPvtsLyoqymvVqpX3wgsv+PqmTJnide7c2atWrZoXExPjtWrVyrvnnnuMtbBx40Zv4MCBXr169byIiAivQYMG3hVXXOEtXry4pOfQx5V9+umnpV7XW2+95UnyQkJCvB9++MHa4/Janud5a9as8RITE73o6GivQYMGXnp6uvfkk08aH3FcVFTknXbaad7EiRNLndep7tBH3v3v//6v169fPy8+Pt6rXr26N2LECGPdvvrqq97ZZ5/tRUdHe02aNPGmT5/uzZ0717jvh/t4wq+//trr1q2bFxMT40kq+TkV/Mi7375mly5dvJiYGK9q1ape586dvWeffbbk68GPvDvk8ccf9zp06ODFxMR48fHxXtu2bb2xY8d6P/30U5n3RP//EZ+2Pzh6WHt+hz4q0vbH9jqoONae3+zZs72uXbt6tWrV8sLDw73atWt7V155pff+++8f9jiUH2uvbHzE8bHB2vO7++67vXbt2nkJCQleRESE16hRI+/vf/+79/PPPx/2uMoW4nmHeT4HOAkUFhaqfv36uvLKK/Xkk086H1dUVKTWrVurf//+zk+wwO7ll1/Wddddp40bN5ItUIqUlBSlpqbql19+4Wk0/K5Ye6gsrD1UFtYeKgtr7+RwUmWiADYvv/yyfvnlFw0cOLBcx4WFhSktLU1z5sxRTk7OMZrdqWH69OkaMWIEGygAAAAATmgnVSbK4RQUFGjXrl2H7UlISCD1/CTy8ccfa82aNUpPT1f79u2VmJhY7nMMGDDA6dN8cHgrV66s7CkAAAAAwBE7ZTZRPvzwQyP0MygzM1ODBg36fSaEY+6RRx7R008/rXbt2mnevHmVPR0AAAAAwAnulMlE2b17d8lHrJamTZs2/LoBAAAAAACwOmU2UQAAAAAAAI4EwbIAAAAAAAAO2EQBAAAAAABw4BwsGx5utlb0N4Fsx4WEhFToXK7nd2GbQ7DmOndbX7B2JNfscq4jmatLz+/1m2BJSUlGLSoqyje2rc8pU6YYtcmTJxu1rKws33jGjBlGz6RJk4xaZGSkUSsqKvKNMzIyjJ5bbrnFqNk+Ferhhx/2jceNG2f02N6D4PVIUlxcnG+cnp5u9NjY1sv48eN94+nTpxs9tvcsOjq6zNqBAweMntBQc6/Xdi8AAAAA4FjjSRQAAAAAAAAHbKIAAAAAAAA4YBMFAAAAAADAgfNHHIeFhVXoBU6kT1CuaF5IRc9/LM99tM9fmZkoycnJRi0tLc03tmWdPPjgg0ZtzJgxRi0iIsI3Li4uNnpsmSjB/BPbXPPz842eadOmGbWJEycatWDui+0abe9BSkpKmTXb9djmaruHwT7b69nuYfA9s83Dln9iy1IJ5rIAAAAAwO+BJ1EAAAAAAAAcsIkCAAAAAADggE0UAAAAAAAAB86ZKOHh4UatopkYFT3OlvtR0fO7nquir3ein9+l5/fKRLFliARzTGwZH3l5eUbNlu0TzDax3VuXPA+bYK6JJN1xxx1GrVatWkbtl19+KfNcU6dONWq2+QfzVOLi4oyeXbt2GbX09HSjNnbsWKMWNGPGDKNmy7aZMmWKb2y7N7GxsUbNlsMCAAAAAMcaT6IAAAAAAAA4YBMFAAAAAADAAZsoAAAAAAAADthEAQAAAAAAcGCmxf4ObMGXwZBSl57S+irS4+pIAlYrOo+jOf8TUU5OjlELBqra3oPIyEijduuttxq1YHBplSpVjB5bkGkw3FaSCgsLfeMxY8aU+XqSlJuba9SC4a8FBQVlvl5pcz1w4IBvbAtwtd0vW4hs8Lpt69O1FgybtQX42o4jWBYAAABAZeBJFAAAAAAAAAdsogAAAAAAADhgEwUAAAAAAMABmygAAAAAAAAOKiVY1iWI1TWs1SYYRFlcXGz0hIebl163bl2jdvvtt/vGmzdvNnoee+yxcs6wdBUNz63ocSeCoqIioxYMILW9x/fee69Ra9iwoVHbuXOnb7x3716jJxiAKkm7d+82avfdd59vbAuMjYqKMmr79u0zasEAWtu8Jk2aZNSCIbKSGcSblJRk9ISGmnuqYWFhRi0rK8s3tq1/2/1yqdnmPn36dKMGAAAAAJWBJ1EAAAAAAAAcsIkCAAAAAADggE0UAAAAAAAAB2yiAAAAAAAAODjmwbIVDYi1haLazuVSq1KlitHz3HPPGbWePXsatcjISN/YFnIZERFh1AoKCoxakO0aKxoGeyQhssFjjyTU91iwBcvOmDHDN77rrruMnlGjRhm1sWPHGrXCwkLfOD093ejJyckxalWrVjVqQQkJCUbNtl5sQcfB98F2nO29uueee4zauHHjfOOMjAyjJyUlxajZgmUfeugh39gWUmsLkZ08ebJRS01N9Y0nTpxo9Ozfv9+oAQAAAEBl4EkUAAAAAAAAB2yiAAAAAAAAOGATBQAAAAAAwEGI5xiA4ZLZcCSC53LNRHE5V2JiotHz1ltvGTXbawav25bPsWvXLqP29ddfl1mzZUTs3LnTqBUXFxu1oKP5Xri83tF+zcOJjY01anl5eb5xaKi5H2i7jmAGh+1cwbwVyZ4zEjxOknJzc33jNWvWGD0dOnQwalOnTjVqwfnbMktsOSk2wbk++eSTRs+QIUOczh8TE+Mb274nbHO15dYE84ps79mBAweMmi23BgAAAACONZ5EAQAAAAAAcMAmCgAAAAAAgAM2UQAAAAAAABywiQIAAAAAAODATIs9jrmGzTZq1Mg3fvbZZ42esLAwo2YLJ3WZQ82aNY1a165dy6y1b9/e6JkyZYpRe/31141aMIDzaIa8Hkmo77EwduxYoxYMiLUFkmZkZBi1rKwsoxa8tkmTJhk927dvN2rVq1c3asEg1jlz5hg9p59+ulGzCV6jbc3ecccdRi0uLs6o7dmzxze23a+vvvrKqL322mtGLRgQW61aNaPHFjZrC6cOvh8PPPCA0TNq1CijBgAAAACVgSdRAAAAAAAAHLCJAgAAAAAA4IBNFAAAAAAAAAdsogAAAAAAADiolGBZW0ipLczU5bhzzjnHqH344Ye+cUxMTDlm57d//37f2BbIGRUVZdRsfcHg2o4dOxo9Q4YMMWpbt241amvXrvWNDxw4YPS4hsFWZmisC9v80tPTfeOCggKjJykpyakWGxvrG9tCUW3hqfv27Stzri1atDB6Ksp1HaelpRm14PfXtGnTjJ7Zs2cbtW3bthm1GTNm+MbB90KSxo8fb9Rs3yfBedjmbvteAgAAAIDKwJMoAAAAAAAADthEAQAAAAAAcMAmCgAAAAAAgAM2UQAAAAAAABwc82DZioab2o6zhXS+++67Ri06Oto3dgl5lczATElKTU31jZs0aWL0fPTRR0YtLi7OqLkEZF555ZVGrUGDBkate/fuvnFhYaHR43rvg6Gjx1vQrC00NxhAOnXqVKMnJSXFqLncpypVqhg9e/fuNWq2MGRbAK0Ll0DVnJwco8e2jidPnmzUJk6cWOYcRowYYdTOPfdco/bqq6/6xrb7bLseWxDvpEmTfOPc3Fyjx/Z+AAAAAEBl4EkUAAAAAAAAB2yiAAAAAAAAOGATBQAAAAAAwEGI5xiAER5uxqe4HFrRTJQePXoYPXPnzjVq9evXN2rBrApbFsmWLVuM2vnnn2/UfvnlF3OyAb179zZqbdq0MWr33XdfmfOy3S9b7sXIkSN940ceecTocclgsbHNwbV2LNiyR4K5HzVr1jR6srKyjFpycrJRC+apZGdnGz3jx483avHx8UYtmAViywv54YcfjNr8+fONmi3bJMiWdbJz506jFvw+yc/PN3qioqKM2qhRo4za7NmzfWNb1kl6erpRs93DunXr+sbBjBTJngVzvOX2AAAAADg18CQKAAAAAACAAzZRAAAAAAAAHLCJAgAAAAAA4IBNFAAAAAAAAAfOwbJhYWEVegHXAMhatWr5xh9++KHR06JFiwqdf9euXUatYcOGRq2goKBC53e9xmAA7eOPP2701KtXz6jZ7v3GjRt9486dOxs9toBUFydCsGxQRESEUTtw4IBRswWxxsTElHmc7T2wBaUGA5h37Nhh9MyaNcuoudxf2324//77jVpSUpJR+/LLL31jW5CtLSjXdr+C97qoqMjosQVR2wKSMzIyfOPCwkKjxxZuO336dKMGAAAAAMcaT6IAAAAAAAA4YBMFAAAAAADAAZsoAAAAAAAADthEAQAAAAAAcGCmP5bCFmpZ0WBR23GtW7f2jZs0aWL0FBcXGzVbWGWwzxbgaguwdOEasGq7X6+//rpv7BqY2bRpU6MWDNkdMGCA0fPYY485zctFRY87VoKBpGlpaUaPrZaTk2PUguvFts5s179///4yX7Nq1apGz8yZM42aLaQ2JSXFqAWlpqYaNdvaPuecc3zjm2++2eiZOnVqma9n8/PPPxu1Ro0aGTXbXJOTk33jSZMmGT2PPvqoUSNYFgAAAEBl4EkUAAAAAAAAB2yiAAAAAAAAOGATBQAAAAAAwAGbKAAAAAAAAA6cg2WPJltI5/bt233joqIioyc83JyuLdT1mWee8Y0nTpxo9NgCaSsalFvR0NUlS5YYtQsvvNCojRgxosxznX322UbNNfDWRUXvzdEQGRlp1JKSknzjsLCwMnske1jrE0884RsPHjzY6ImJiTFqcXFxRq1t27a+8Y8//ug0h+zsbKMWDHrNy8szemw121yD3zvPPfec0WNbQ7ZrDL5ms2bNjB7bvbcFKdvCeYNsobsAAAAAUBl4EgUAAAAAAMABmygAAAAAAAAO2EQBAAAAAABwcFQzUVxzM2x9w4YN840jIiKczlVYWGjU5s+f7xvbckAqOtcjOVfw2OLiYqNnw4YNRs12jcGMi6uuusromTBhglGzZW9UNCfl95KammrU8vPzfePo6Gijx5alYcvguOGGG3zjyZMnGz333HOPUdu3b59Ry8zM9I0vueQSoyc3N9eo2XJMgn2274lp06YZNdv7WVBQUOa5bDlEtuyg4LEDBw40eu6//36j9vDDD5f5mrb8ouB7DQAAAACVhSdRAAAAAAAAHLCJAgAAAAAA4IBNFAAAAAAAAAdsogAAAAAAADg4qsGytkBLW3iqLawyGE5p67EFuI4dO9aovfPOO2XOy5XLsa7ndwmgfeWVV4za8OHDjVrLli1943r16hk9V199tVGbO3dumXM43tgCcoOhsbZ1ZmN7r0aPHu0bT5o0yeiJiooyavfee69Re/fdd33j7t27Gz22tW0LdY2MjPSN09PTjR5b6LBt/sFg3DFjxhg9s2bNMmp33nlnma9Zp04do8e29urWrWvU0tLSypxDUlKSUQMAAACAysCTKAAAAAAAAA7YRAEAAAAAAHDAJgoAAAAAAIADNlEAAAAAAAAcOAfL2gI5XYJSbcfZQlDj4+Ndp+KzYcOGCh3nMnfX4yoaXGs7bvPmzUbtk08+MWpnnHFGmefq1KmTUXvyySfLnEdF3+tjxfba0dHRvvHUqVONHlvosC1YNyYmxjcODze/LWxhrX379jVqERERvrEtfNZ2rt27dxu1+vXr+8a2kFfb941L2GxYWJjRYwswbtSokVHbtGmTb2xbLzVq1DBqwRBZyXyPbAG+e/fuNWoAAAAAUBl4EgUAAAAAAMABmygAAAAAAAAO2EQBAAAAAABwwCYKAAAAAACAA+dg2eLi4jJ7XMNH+/TpY9SCgZyuc7AFsVZ0Xi5cQ2RdXtN1XqGh5l6XyzxsAb620FSX97YyJSUlGbWioiLf+O677zZ6Jk+ebNTS09PLfL2UlBSjNm3aNKO2ZcsWozZ69Ogyj8vJyTFqGRkZRi05Odk3rlKlitFz4MABo2YLcA1ety2QNj8/36ht3LjRqAXvte2e2sJtg2HAkhlwm5CQYPRkZ2cbNQAAAACoDDyJAgAAAAAA4IBNFAAAAAAAAAdsogAAAAAAADhwzkSxZXBUNPdjw4YNri/rs3v3bqO2bt26Cp3LpqLZKa45KS59wYwISfruu++MWnCutnO/8sorFZrX8ZaRYssVSU1N9Y1t+Sc2K1asMGoXXHBBmccNGjTIqE2YMMGoXX311b6x7X2pWbOmUQvmn0jme2xbn7b1ctdddxk1lx5bvsr06dONWjAzxpbVsm3bNqNmy0mJi4vzjceMGWP02LJUbLkvAAAAAHCs8SQKAAAAAACAAzZRAAAAAAAAHLCJAgAAAAAA4IBNFAAAAAAAAAchnmOaani4mUFb0WDZBg0aGLXNmzf7xrbAzGCPJJ155plGraCgoMx52djm6hoaW5Hz216vTZs2Ru3zzz83ahEREWWe65prrjFqL7/8coXm5Vo7FmwBrjNnzvSN09PTjZ7QUHOP8JFHHjFqw4YN841tAatDhgwxak2bNjVqI0aM8I1jYmKMnv379xu1yMhIoxYVFeUb24JZgwG7kj1kN7iObfcmuKYke5hz8GfB1KlTjZ7rrrvOqLVu3brM18zOzjZ6bPdw0qRJRg0AAAAAjjWeRAEAAAAAAHDAJgoAAAAAAIADNlEAAAAAAAAcsIkCAAAAAADg4JgHy9oUFxcbtU2bNvnGTZo0cXq9YCioJP3zn//0jW3hsLaabV7BPtscbPcmNjbWqF122WW+8YABA4yePn36GDVbCGiQLZDz4osvNmqrV682asd7sGx0dLRRGz9+fJk9SUlJRs0Wunr99df7xi1btjR6UlJSjNq+ffuMWnx8vG+cm5tr9EyfPt2oBa9HkqpWreob79271+gJhs9KbuvFNaT2vvvuM2p5eXm+sS3I2RaUa7v3GRkZvrHtPbP5vdYeAAAAAPwWT6IAAAAAAAA4YBMFAAAAAADAAZsoAAAAAAAADthEAQAAAAAAcHDMg2VtYa02wdDJ5ORko8cWmLlnzx6jFgxwXbt2rdHToEEDo2YLAe3cubNvfO2115bZI0k1a9Y0ajExMUbtaBk3bpxRmzlzplGzvR/He7CsbS2EhYWVeZwtPDg/P7/M42whtRMnTjRqthDUhIQE3zgYwipJzz33nFHLyckxasHQZFtYq209NmrUyKilpaX5xrb7Z/seLyoqMmrBtWYLpLUdZzv/lClTjJoLgmUBAAAAVAaeRAEAAAAAAHDAJgoAAAAAAIADNlEAAAAAAAAcHPNMFNcsjeD5BwwYYPRkZmYatYiICKOWnZ1d5ryC2RXHi8LCQqO2atUqo/bBBx/4xsHMC8me8eLieMtEsWWbBDNKbBkctgwRW35HsGY7V7Vq1YyaLcfkjjvu8I1nz55t9Bw4cKDM4yQpLi7ON05JSTF6XLJhJPMe2uYQHx9v1Lp3727Uli5d6hvPmDHD6Ln99tuNmu17NTgP28+Z2NhYo3bXXXcZNQAAAAA41ngSBQAAAAAAwAGbKAAAAAAAAA7YRAEAAAAAAHDAJgoAAAAAAIADM8WxFLZwz4oGi4aGmns3wTDPZ555xuj59ddfjZotkPPiiy/2jffv32/02II1bSGdwet2vQ+2WnD+//mf/2n0LFiwwKh99NFHRi2ooKCgzJ6TSfB6q1evbvRMmjTJqEVFRRm1YADvvffea/T06NHDqLVr186oTZ061TcePXq00VO1alWjZgtnDa5HW8DqyJEjjZptbc+aNcs3jo6ONnpsQbkXXHCBUQt+/9oCjG33OXhvJCk5Odk3ts193759Rg0AAAAAKgNPogAAAAAAADhgEwUAAAAAAMABmygAAAAAAAAO2EQBAAAAAABwEOI5psOGh5sZtC6H2npcwlltx9kCaSMiIoxa8+bNfePatWsbPRkZGUbtzDPPNGoffPCBb7x06VKj57333jNqO3bsMGq7du3yjW33wXaNNi73y3b+ipy7PLVjIRg+KpnBqIWFhUaPbX62cyUlJfnGtrVx9913GzXb2guGGNt6IiMjnc7VrFkz3/ibb74xevbs2WPUYmJinGpB+fn5Ri09Pd2oTZ8+3Te2Bcva7nNKSopRS01N9Y1ta7a4uNio/V5rDwAAAAB+iydRAAAAAAAAHLCJAgAAAAAA4IBNFAAAAAAAAAdsogAAAAAAADiolGDZ41VYWJhRKyoqqtC5XMJzj+Q4l9DYo3nvKzNYNjY21qjl5eX5xpMnTzZ6bO9nMPhVMq/D9no5OTlGzRbWGgxBtZ3L9V4Gw2bHjh1bZo9kBuVK5joOhsNK9nBe2/d9MGTX1jNlyhSjZnvN7Oxs39gWSBsVFWXUbO8jAAAAABxrPIkCAAAAAADggE0UAAAAAAAAB2yiAAAAAAAAODDDDI7A8Zp/4pozYsuEcMkesTnW9yJ4/orO80QwadIkozZhwgTfOD8/3+h56KGHjJotLyQ1NdU3TklJMXps+Sq2jI9gVkdkZKTRY8v4sOWdBGt33XWX0VOtWjWjFswskcz1kZGRYfSMHz/eqNm+JxISEnzj3Nxco8f2fgTzTyTzftne6/T0dKMGAAAAAJWBJ1EAAAAAAAAcsIkCAAAAAADggE0UAAAAAAAAB2yiAAAAAAAAOAjxHBNQw8PNDNrfO0jW9nquobEVdTwEtrpcj+s8j+a9KS4uPmrnOhxbCGpMTIxvvG/fPqMnOTnZqNmCZYPhqTNmzHA6zhaeev/99/vGRUVFRo/te2nixIlGLfie2q7HVXD+tvcuNNTcU61du7ZR27Nnj29sC5+tXr26URs9erRRC4bzBoNmJft1H68h1gAAAABObjyJAgAAAAAA4IBNFAAAAAAAAAdsogAAAAAAADhgEwUAAAAAAMCBc7AsAAAAAADAqYwnUQAAAAAAABywiQIAAAAAAOCATRQAAAAAAAAHbKIAAAAAAAA4YBMFAAAAAADAAZsoAAAAAAAADthEAQAAAAAAcMAmCgAAAAAAgAM2UQAAAAAAABz8H5bG3zVPIhyyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x300 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(img, title=None):\n",
    "    img = img.detach().cpu().squeeze(0)\n",
    "    img = img.clamp(-1, 1)\n",
    "    img = (img + 1) / 2\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.subplot(1, num_particles+2, 1)\n",
    "show(x_true, \"x_true\")\n",
    "plt.subplot(1, num_particles+2, 2)\n",
    "show(y, \"y (observed)\")\n",
    "for i in range(num_particles):\n",
    "    plt.subplot(1, num_particles+2, i+3)\n",
    "    show(particles[i], f\"particle {i+1}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859e8f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 135.72it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 110.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SMC: guidance=0.001, sigma=0.03, steps=50\n",
      "Running SMC: guidance=0.001, sigma=0.03, steps=75\n",
      "Running SMC: guidance=0.001, sigma=0.05, steps=50\n",
      "Running SMC: guidance=0.001, sigma=0.05, steps=75\n",
      "Running SMC: guidance=0.005, sigma=0.03, steps=50\n",
      "Running SMC: guidance=0.005, sigma=0.03, steps=75\n",
      "Running SMC: guidance=0.005, sigma=0.05, steps=50\n",
      "Running SMC: guidance=0.005, sigma=0.05, steps=75\n",
      "Running SMC: guidance=0.01, sigma=0.03, steps=50\n",
      "Running SMC: guidance=0.01, sigma=0.03, steps=75\n",
      "Running SMC: guidance=0.01, sigma=0.05, steps=50\n",
      "Running SMC: guidance=0.01, sigma=0.05, steps=75\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline, DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ========================\n",
    "# 1️⃣ Charger le modèle MNIST\n",
    "# ========================\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "pipe.unet.eval()\n",
    "\n",
    "scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# ========================\n",
    "# 2️⃣ Générer une image MNIST\n",
    "# ========================\n",
    "with torch.no_grad():\n",
    "    x_true_pil = pipe(batch_size=1).images[0]\n",
    "\n",
    "to_tensor = T.ToTensor()\n",
    "x_true = to_tensor(x_true_pil).to(device)\n",
    "x_true = x_true * 2 - 1  # [-1,1]\n",
    "\n",
    "# ========================\n",
    "# 3️⃣ Masque et observation\n",
    "# ========================\n",
    "def create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=0.05):\n",
    "    _, H, W = x_true.shape\n",
    "    spatial_mask = (torch.rand(H, W, device=x_true.device) > missing_ratio).float()\n",
    "    mask = spatial_mask.unsqueeze(0)\n",
    "    noise = sigma_noise * torch.randn_like(x_true)\n",
    "    y = mask * x_true + noise\n",
    "    return mask, y\n",
    "\n",
    "# Exemple observation\n",
    "sigma_noise_default = 0.05\n",
    "mask, y = create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=sigma_noise_default)\n",
    "\n",
    "# ========================\n",
    "# 4️⃣ Gradient et log-likelihood\n",
    "# ========================\n",
    "def log_likelihood_grad(x, y, mask, sigma_noise):\n",
    "    return mask * (y - mask * x) / (sigma_noise ** 2)\n",
    "\n",
    "def log_likelihood(x, y, mask, sigma_noise):\n",
    "    return -0.5 * ((mask * (y - mask * x))**2 / (sigma_noise**2)).sum(dim=[1,2,3])\n",
    "\n",
    "# ========================\n",
    "# 5️⃣ SMC-guided sampling avec sauvegarde des étapes\n",
    "# ========================\n",
    "@torch.no_grad()\n",
    "def smc_guided_sampling(pipe, y, mask, sigma_noise, num_particles=5,\n",
    "                        guidance_scale=0.01, num_steps=50,\n",
    "                        save_dir=\"results\", show_intermediate=True):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    _, H, W = y.shape\n",
    "    particles = torch.randn(num_particles, 1, H, W, device=y.device)  # x_T\n",
    "    weights = torch.ones(num_particles, device=y.device) / num_particles\n",
    "\n",
    "    scheduler.set_timesteps(num_steps)\n",
    "    timesteps = scheduler.timesteps\n",
    "\n",
    "    for t_idx, t in enumerate(timesteps):\n",
    "        for i in range(num_particles):\n",
    "            x_t = particles[i:i+1]\n",
    "\n",
    "            # Prédiction epsilon\n",
    "            eps = pipe.unet(x_t, t)[\"sample\"]\n",
    "\n",
    "            # Reverse step DDPM\n",
    "            alpha_t = scheduler.alphas_cumprod[t]\n",
    "            beta_t = 1 - alpha_t\n",
    "            x_prev = (1 / torch.sqrt(alpha_t)) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * eps)\n",
    "\n",
    "            # Guidance\n",
    "            grad = log_likelihood_grad(x_prev, y, mask, sigma_noise)\n",
    "            x_prev = x_prev + guidance_scale * grad\n",
    "\n",
    "            # Ajouter bruit sauf dernier step\n",
    "            if t_idx < len(timesteps) - 1:\n",
    "                x_prev = x_prev + torch.sqrt(beta_t) * torch.randn_like(x_prev)\n",
    "\n",
    "            particles[i:i+1] = x_prev\n",
    "\n",
    "        # Mettre à jour poids\n",
    "        logw = log_likelihood(particles, y, mask, sigma_noise)\n",
    "        logw = logw - logw.max()\n",
    "        w = torch.exp(logw)\n",
    "        w = w / w.sum()\n",
    "        weights = w\n",
    "\n",
    "        # Resampling si ESS faible\n",
    "        ess = 1.0 / (weights**2).sum()\n",
    "        if ess < num_particles / 2:\n",
    "            indices = torch.multinomial(weights, num_particles, replacement=True)\n",
    "            particles = particles[indices]\n",
    "            weights = torch.ones(num_particles, device=y.device) / num_particles\n",
    "\n",
    "        # Sauvegarde et affichage intermédiaire\n",
    "        if show_intermediate and t_idx % max(1, num_steps // 5) == 0:\n",
    "            plt.figure(figsize=(15, 3))\n",
    "            plt.subplot(1, num_particles+2, 1)\n",
    "            show(x_true, \"x_true\")\n",
    "            plt.subplot(1, num_particles+2, 2)\n",
    "            show(y, \"y\")\n",
    "            for j in range(num_particles):\n",
    "                plt.subplot(1, num_particles+2, j+3)\n",
    "                show(particles[j], f\"step {t_idx} particle {j+1}\")\n",
    "            plt.suptitle(f\"Step {t_idx} / {num_steps} | guidance {guidance_scale} | sigma {sigma_noise}\")\n",
    "            plt.savefig(os.path.join(save_dir, f\"step_{t_idx}_g{guidance_scale}_s{sigma_noise}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "    return particles, weights\n",
    "\n",
    "# ========================\n",
    "# 6️⃣ Fonction affichage\n",
    "# ========================\n",
    "def show(img, title=None):\n",
    "    img = img.detach().cpu().squeeze(0)\n",
    "    img = img.clamp(-1, 1)\n",
    "    img = (img + 1) / 2\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "# ========================\n",
    "# 7️⃣ Tester plusieurs combinaisons de paramètres\n",
    "# ========================\n",
    "guidance_scales = [0.001, 0.005, 0.01]\n",
    "num_steps_list = [50, 75]\n",
    "sigma_noises = [0.03, 0.05]\n",
    "\n",
    "results_dir = \"smc_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "for g in guidance_scales:\n",
    "    for s in sigma_noises:\n",
    "        for n in num_steps_list:\n",
    "            print(f\"Running SMC: guidance={g}, sigma={s}, steps={n}\")\n",
    "            particles, weights = smc_guided_sampling(\n",
    "                pipe, y, mask, sigma_noise=s,\n",
    "                num_particles=5,\n",
    "                guidance_scale=g,\n",
    "                num_steps=n,\n",
    "                save_dir=results_dir,\n",
    "                show_intermediate=True\n",
    "            )\n",
    "            # Sauvegarde finale\n",
    "            for i, p in enumerate(particles):\n",
    "                plt.figure(figsize=(2,2))\n",
    "                show(p, f\"particle_{i+1}_g{g}_s{s}_n{n}\")\n",
    "                plt.savefig(os.path.join(results_dir, f\"particle_{i+1}_g{g}_s{s}_n{n}.png\"))\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc3357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 125.12it/s]\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 131.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SMC: g_init=0.001, g_final=0.0005, sigma=0.04\n",
      "Running SMC: g_init=0.001, g_final=0.0005, sigma=0.05\n",
      "Running SMC: g_init=0.001, g_final=0.0005, sigma=0.06\n",
      "Running SMC: g_init=0.001, g_final=0.0007, sigma=0.04\n",
      "Running SMC: g_init=0.001, g_final=0.0007, sigma=0.05\n",
      "Running SMC: g_init=0.001, g_final=0.0007, sigma=0.06\n",
      "Running SMC: g_init=0.001, g_final=0.001, sigma=0.04\n",
      "Running SMC: g_init=0.001, g_final=0.001, sigma=0.05\n",
      "Running SMC: g_init=0.001, g_final=0.001, sigma=0.06\n",
      "Running SMC: g_init=0.0015, g_final=0.0005, sigma=0.04\n",
      "Running SMC: g_init=0.0015, g_final=0.0005, sigma=0.05\n",
      "Running SMC: g_init=0.0015, g_final=0.0005, sigma=0.06\n",
      "Running SMC: g_init=0.0015, g_final=0.0007, sigma=0.04\n",
      "Running SMC: g_init=0.0015, g_final=0.0007, sigma=0.05\n",
      "Running SMC: g_init=0.0015, g_final=0.0007, sigma=0.06\n",
      "Running SMC: g_init=0.0015, g_final=0.001, sigma=0.04\n",
      "Running SMC: g_init=0.0015, g_final=0.001, sigma=0.05\n",
      "Running SMC: g_init=0.0015, g_final=0.001, sigma=0.06\n",
      "Running SMC: g_init=0.002, g_final=0.0005, sigma=0.04\n",
      "Running SMC: g_init=0.002, g_final=0.0005, sigma=0.05\n",
      "Running SMC: g_init=0.002, g_final=0.0005, sigma=0.06\n",
      "Running SMC: g_init=0.002, g_final=0.0007, sigma=0.04\n",
      "Running SMC: g_init=0.002, g_final=0.0007, sigma=0.05\n",
      "Running SMC: g_init=0.002, g_final=0.0007, sigma=0.06\n",
      "Running SMC: g_init=0.002, g_final=0.001, sigma=0.04\n",
      "Running SMC: g_init=0.002, g_final=0.001, sigma=0.05\n",
      "Running SMC: g_init=0.002, g_final=0.001, sigma=0.06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline, DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ========================\n",
    "# 1️⃣ Charger le modèle MNIST\n",
    "# ========================\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "pipe.unet.eval()\n",
    "scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# ========================\n",
    "# 2️⃣ Générer image MNIST\n",
    "# ========================\n",
    "with torch.no_grad():\n",
    "    x_true_pil = pipe(batch_size=1).images[0]\n",
    "\n",
    "to_tensor = T.ToTensor()\n",
    "x_true = to_tensor(x_true_pil).to(device)\n",
    "x_true = x_true * 2 - 1  # [-1,1]\n",
    "\n",
    "# ========================\n",
    "# 3️⃣ Masque et observation\n",
    "# ========================\n",
    "def create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=0.05):\n",
    "    _, H, W = x_true.shape\n",
    "    spatial_mask = (torch.rand(H, W, device=x_true.device) > missing_ratio).float()\n",
    "    mask = spatial_mask.unsqueeze(0)\n",
    "    noise = sigma_noise * torch.randn_like(x_true)\n",
    "    y = mask * x_true + noise\n",
    "    return mask, y\n",
    "\n",
    "mask, y = create_inpainting_observation(x_true, missing_ratio=0.6, sigma_noise=0.05)\n",
    "\n",
    "# ========================\n",
    "# 4️⃣ Gradient\n",
    "# ========================\n",
    "def log_likelihood_grad(x, y, mask, sigma_noise):\n",
    "    return mask * (y - mask * x) / (sigma_noise ** 2)\n",
    "\n",
    "# ========================\n",
    "# 5️⃣ Fonction affichage\n",
    "# ========================\n",
    "def show(img, title=None):\n",
    "    img = img.detach().cpu().squeeze(0)\n",
    "    img = img.clamp(-1, 1)\n",
    "    img = (img + 1) / 2\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "# ========================\n",
    "# 6️⃣ SMC-guided sampling\n",
    "# ========================\n",
    "@torch.no_grad()\n",
    "def smc_guided_sampling(pipe, y, mask, sigma_noise, num_particles=5,\n",
    "                        guidance_init=0.002, guidance_final=0.0005,\n",
    "                        num_steps=20, save_dir=\"smc_grid\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    _, H, W = y.shape\n",
    "    particles = torch.randn(num_particles, 1, H, W, device=y.device)\n",
    "    weights = torch.ones(num_particles, device=y.device) / num_particles\n",
    "\n",
    "    scheduler.set_timesteps(num_steps)\n",
    "    timesteps = scheduler.timesteps\n",
    "\n",
    "    guidance_schedule = torch.linspace(guidance_init, guidance_final, num_steps)\n",
    "\n",
    "    for t_idx, t in enumerate(timesteps):\n",
    "        guidance_scale = guidance_schedule[t_idx]\n",
    "\n",
    "        for i in range(num_particles):\n",
    "            x_t = particles[i:i+1]\n",
    "            eps = pipe.unet(x_t, t)[\"sample\"]\n",
    "\n",
    "            alpha_t = scheduler.alphas_cumprod[t]\n",
    "            beta_t = 1 - alpha_t\n",
    "            x_prev = (1 / torch.sqrt(alpha_t)) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * eps)\n",
    "\n",
    "            grad = log_likelihood_grad(x_prev, y, mask, sigma_noise)\n",
    "            x_prev = x_prev + guidance_scale * grad\n",
    "\n",
    "            if t_idx < len(timesteps) - 1:\n",
    "                x_prev = x_prev + torch.sqrt(beta_t) * torch.randn_like(x_prev)\n",
    "\n",
    "            particles[i:i+1] = x_prev\n",
    "\n",
    "        # Sauvegarde intermédiaire\n",
    "        plt.figure(figsize=(15,3))\n",
    "        plt.subplot(1, num_particles+2, 1)\n",
    "        show(x_true, \"x_true\")\n",
    "        plt.subplot(1, num_particles+2, 2)\n",
    "        show(y, \"y\")\n",
    "        for j in range(num_particles):\n",
    "            plt.subplot(1, num_particles+2, j+3)\n",
    "            show(particles[j], f\"step {t_idx} particle {j+1}\")\n",
    "        plt.suptitle(f\"Step {t_idx} | g_init={guidance_init:.4f} | g_final={guidance_final:.4f} | sigma={sigma_noise}\")\n",
    "        plt.savefig(os.path.join(save_dir, f\"step_{t_idx}_g{guidance_init}_{guidance_final}_s{sigma_noise}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    return particles\n",
    "\n",
    "# ========================\n",
    "# 7️⃣ Grille de paramètres\n",
    "# ========================\n",
    "guidance_inits = [0.001, 0.0015, 0.002]\n",
    "guidance_finals = [0.0005, 0.0007, 0.001]\n",
    "sigma_noises = [0.04, 0.05, 0.06]\n",
    "\n",
    "num_particles = 5\n",
    "num_steps = 20\n",
    "results_dir = \"smc_grid_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# ========================\n",
    "# 8️⃣ Boucle sur la grille\n",
    "# ========================\n",
    "for g_init in guidance_inits:\n",
    "    for g_final in guidance_finals:\n",
    "        for s in sigma_noises:\n",
    "            print(f\"Running SMC: g_init={g_init}, g_final={g_final}, sigma={s}\")\n",
    "            particles = smc_guided_sampling(pipe, y, mask, sigma_noise=s,\n",
    "                                            num_particles=num_particles,\n",
    "                                            guidance_init=g_init,\n",
    "                                            guidance_final=g_final,\n",
    "                                            num_steps=num_steps,\n",
    "                                            save_dir=results_dir)\n",
    "\n",
    "            # Visualiser moyenne et std\n",
    "            mean_particle = particles.mean(dim=0)\n",
    "            std_particle = particles.std(dim=0)\n",
    "            plt.figure(figsize=(6,3))\n",
    "            plt.subplot(1,2,1)\n",
    "            show(mean_particle, f\"mean g_init={g_init} g_final={g_final} sigma={s}\")\n",
    "            plt.subplot(1,2,2)\n",
    "            show(std_particle, \"std\")\n",
    "            plt.savefig(os.path.join(results_dir, f\"mean_std_g{g_init}_{g_final}_s{s}.png\"))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3bfb8",
   "metadata": {},
   "source": [
    "## **Article version** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1500a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import DDPMPipeline\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a7aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 139.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "pipe.unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b807b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mcg_diff_smc_sampler(\n",
    "    score_model,       # pre‑trained score model (provides score estimates)\n",
    "    A,                 # forward linear operator (e.g., masking matrix)\n",
    "    AT,                # adjoint operator of A\n",
    "    y,                 # measurement data\n",
    "    sigma_y,           # measurement noise std\n",
    "    timesteps,         # diffusion timesteps schedule\n",
    "    num_particles=10,\n",
    "    resample_threshold_ratio=0.5,\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Monte Carlo Guided Diffusion (MCGDiff) sampler for Bayesian linear inverse problems.\n",
    "    This matches the algorithm structure described in Cardoso et al. (MCGDiff). :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "    score_model: must implement score_model.score(x, t) returning score estimate.\n",
    "    A, AT: functions implementing forward and adjoint measurement operations.\n",
    "    y: observed measurement.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize particles\n",
    "    particles = torch.randn(num_particles, *y.shape, device=device)\n",
    "    log_weights = torch.zeros(num_particles, device=device)\n",
    "\n",
    "    # iterate backwards through diffusion steps\n",
    "    for t in reversed(timesteps):\n",
    "        # dt, beta, sqrt_alpha etc. come from your diffusion schedule\n",
    "        # here we assume `scheduler` holds this information:\n",
    "        alpha_t = scheduler.alphas_cumprod[t]\n",
    "        beta_t = 1 - alpha_t\n",
    "\n",
    "        for i in range(num_particles):\n",
    "            x = particles[i:i+1]\n",
    "\n",
    "            # denoise score\n",
    "            score = score_model.score(x, t)\n",
    "\n",
    "            # propose backward diffusion step\n",
    "            # standard reverse step: (simplified Euler‑Maruyama)\n",
    "            x_mean = (\n",
    "                x / torch.sqrt(alpha_t)\n",
    "                - beta_t / torch.sqrt(1 - alpha_t) * score\n",
    "            )\n",
    "\n",
    "            noise = torch.randn_like(x)\n",
    "            x_next = x_mean + torch.sqrt(beta_t) * noise\n",
    "\n",
    "            # particle becomes proposed sample\n",
    "            particles[i:i+1] = x_next\n",
    "\n",
    "        # compute importance weights (log scale)\n",
    "        # likelihood under measurement model p(y | x) = Normal(A x, sigma_y^2)\n",
    "        Ax = A(particles)\n",
    "        log_likelihood = -0.5 * ((Ax - y).pow(2) / sigma_y**2).flatten(1).sum(dim=1)\n",
    "        log_weights = log_likelihood\n",
    "\n",
    "        # normalize weights\n",
    "        logw_max = log_weights.max()\n",
    "        weights = torch.exp(log_weights - logw_max)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        # effective sample size\n",
    "        ess = 1.0 / (weights**2).sum().item()\n",
    "\n",
    "        # resample if ESS below threshold\n",
    "        if ess < num_particles * resample_threshold_ratio:\n",
    "            indices = torch.multinomial(weights, num_particles, replacement=True)\n",
    "            particles = particles[indices]\n",
    "            weights = torch.ones_like(weights) / num_particles\n",
    "\n",
    "    return particles, weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed32fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 82.94it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MNIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load one MNIST image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[1;32m     12\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     13\u001b[0m     T\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# convert to [0,1] tensor\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[0;32m---> 15\u001b[0m mnist_data \u001b[38;5;241m=\u001b[39m \u001b[43mMNIST\u001b[49m(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     16\u001b[0m x_true, label \u001b[38;5;241m=\u001b[39m mnist_data[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# take the first test image\u001b[39;00m\n\u001b[1;32m     17\u001b[0m x_true \u001b[38;5;241m=\u001b[39m x_true\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [1,1,28,28]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MNIST' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==============================\n",
    "# Load pre-trained DDPM MNIST model\n",
    "# ==============================\n",
    "pipe = DDPMPipeline.from_pretrained(\"1aurent/ddpm-mnist\").to(device)\n",
    "pipe.unet.eval()\n",
    "\n",
    "# ==============================\n",
    "# Load one MNIST image\n",
    "# ==============================\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),  # convert to [0,1] tensor\n",
    "])\n",
    "mnist_data = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "x_true, label = mnist_data[0]  # take the first test image\n",
    "x_true = x_true.to(device).unsqueeze(0)  # [1,1,28,28]\n",
    "\n",
    "# ==============================\n",
    "# Create masked observation (inpainting)\n",
    "# ==============================\n",
    "mask = torch.zeros(28,28, device=device)\n",
    "mask[:, :14] = 1.0  # reveal left half\n",
    "y = x_true * mask  # masked measurement\n",
    "\n",
    "def A(x): return x * mask\n",
    "def AT(x): return x * mask\n",
    "\n",
    "# ==============================\n",
    "# Timesteps and score wrapper\n",
    "# ==============================\n",
    "timesteps = list(range(100))  # example steps\n",
    "\n",
    "class ScoreModelWrapper:\n",
    "    def __init__(self, pipe, timesteps):\n",
    "        self.pipe = pipe\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def score(self, x, t):\n",
    "        if x.ndim == 5:\n",
    "            x = x.squeeze(2)\n",
    "        eps = self.pipe.unet(x, torch.tensor([t], device=x.device))[\"sample\"]\n",
    "        alpha_t = 0.01 + 0.99*t/len(self.timesteps)\n",
    "        return -eps / math.sqrt(1 - alpha_t)\n",
    "\n",
    "score_model = ScoreModelWrapper(pipe, timesteps)\n",
    "\n",
    "# ==============================\n",
    "# Original MCGDiff SMC sampler\n",
    "# ==============================\n",
    "def mcg_diff_smc_sampler(\n",
    "    score_model,\n",
    "    A,\n",
    "    AT,\n",
    "    y,\n",
    "    sigma_y,\n",
    "    timesteps,\n",
    "    num_particles=5,\n",
    "    resample_threshold_ratio=0.5,\n",
    "    device='cuda'\n",
    "):\n",
    "    particles = torch.randn(num_particles, 1, 28, 28, device=device)\n",
    "    saved_particles = []\n",
    "\n",
    "    for t in reversed(timesteps):\n",
    "        for i in range(num_particles):\n",
    "            x = particles[i:i+1]\n",
    "            score = score_model.score(x, t)\n",
    "            alpha_t = 0.01 + 0.99*t/len(timesteps)\n",
    "            beta_t = 1 - alpha_t\n",
    "\n",
    "            # Reverse diffusion proposal\n",
    "            x_mean = x / math.sqrt(alpha_t) - beta_t / math.sqrt(1 - alpha_t) * score\n",
    "            x_next = x_mean + math.sqrt(beta_t) * torch.randn_like(x)\n",
    "            particles[i:i+1] = x_next\n",
    "\n",
    "        # Compute importance weights\n",
    "        Ax = A(particles)\n",
    "        log_weights = -0.5 * ((Ax - y)**2).flatten(1).sum(dim=1)\n",
    "        logw_max = log_weights.max()\n",
    "        weights = torch.exp(log_weights - logw_max)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        # Resample if ESS is low\n",
    "        ess = 1.0 / (weights**2).sum().item()\n",
    "        if ess < num_particles * resample_threshold_ratio:\n",
    "            indices = torch.multinomial(weights, num_particles, replacement=True)\n",
    "            particles = particles[indices]\n",
    "            weights = torch.ones(num_particles, device=device) / num_particles\n",
    "\n",
    "        saved_particles.append(particles.clone().cpu())\n",
    "\n",
    "    return saved_particles, weights.cpu()\n",
    "\n",
    "# ==============================\n",
    "# Run SMC sampler\n",
    "# ==============================\n",
    "saved_particles, final_weights = mcg_diff_smc_sampler(\n",
    "    score_model=score_model,\n",
    "    A=A,\n",
    "    AT=AT,\n",
    "    y=y,\n",
    "    sigma_y=0.0,\n",
    "    timesteps=timesteps,\n",
    "    num_particles=5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Plot results\n",
    "# ==============================\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 7))\n",
    "\n",
    "# Original image\n",
    "axes[0,0].imshow(x_true[0,0].cpu(), cmap='gray')\n",
    "axes[0,0].set_title(\"Original\")\n",
    "axes[0,0].axis(\"off\")\n",
    "\n",
    "# Masked image\n",
    "axes[0,1].imshow(y[0,0].cpu(), cmap='gray')\n",
    "axes[0,1].set_title(\"Masked input\")\n",
    "axes[0,1].axis(\"off\")\n",
    "\n",
    "# Plot particles from first, middle, last timesteps\n",
    "for j, idx in enumerate([0, len(saved_particles)//2, -1]):\n",
    "    particle_set = saved_particles[idx]\n",
    "    for i in range(5):\n",
    "        ax = axes[j,i]\n",
    "        ax.imshow(particle_set[i,0], cmap='gray')\n",
    "        if j==0: ax.set_title(f\"t={idx}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Inpainting with MCGDiff SMC sampler\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
